layer {
  name: "images"
  type: "Input"
  top: "images"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 320
      dim: 544
    }
  }
}
layer {
  name: "Conv_0"
  type: "Convolution"
  bottom: "images"
  top: "1075"
  convolution_param {
    num_output: 3
    bias_term: true
    group: 3
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "Relu_1"
  type: "ReLU"
  bottom: "1075"
  top: "679"
}
layer {
  name: "Conv_2"
  type: "Convolution"
  bottom: "679"
  top: "1078"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_3"
  type: "ReLU"
  bottom: "1078"
  top: "682"
}
layer {
  name: "Conv_4"
  type: "Convolution"
  bottom: "682"
  top: "1081"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_5"
  type: "ReLU"
  bottom: "1081"
  top: "685"
}
layer {
  name: "Conv_6"
  type: "Convolution"
  bottom: "682"
  top: "1084"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_7"
  type: "ReLU"
  bottom: "1084"
  top: "688"
}
layer {
  name: "Conv_8"
  type: "Convolution"
  bottom: "685"
  top: "1087"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_9"
  type: "ReLU"
  bottom: "1087"
  top: "691"
}
layer {
  name: "Conv_10"
  type: "Convolution"
  bottom: "691"
  top: "1090"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 8
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_11"
  type: "ReLU"
  bottom: "1090"
  top: "694"
}
layer {
  name: "Conv_12"
  type: "Convolution"
  bottom: "694"
  top: "1093"
  convolution_param {
    num_output: 8
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_13"
  type: "ReLU"
  bottom: "1093"
  top: "697"
}
layer {
  name: "Add_14"
  type: "Eltwise"
  bottom: "697"
  bottom: "685"
  top: "698"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Concat_15"
  type: "Concat"
  bottom: "698"
  bottom: "688"
  top: "699"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_16"
  type: "Convolution"
  bottom: "699"
  top: "1096"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_17"
  type: "ReLU"
  bottom: "1096"
  top: "702"
}
layer {
  name: "Conv_18"
  type: "Convolution"
  bottom: "702"
  top: "1099"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 16
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "Relu_19"
  type: "ReLU"
  bottom: "1099"
  top: "705"
}
layer {
  name: "Conv_20"
  type: "Convolution"
  bottom: "705"
  top: "1102"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_21"
  type: "ReLU"
  bottom: "1102"
  top: "708"
}
layer {
  name: "Conv_22"
  type: "Convolution"
  bottom: "708"
  top: "1105"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_23"
  type: "ReLU"
  bottom: "1105"
  top: "711"
}
layer {
  name: "Conv_24"
  type: "Convolution"
  bottom: "708"
  top: "1108"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_25"
  type: "ReLU"
  bottom: "1108"
  top: "714"
}
layer {
  name: "Conv_26"
  type: "Convolution"
  bottom: "711"
  top: "1111"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_27"
  type: "ReLU"
  bottom: "1111"
  top: "717"
}
layer {
  name: "Conv_28"
  type: "Convolution"
  bottom: "717"
  top: "1114"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 16
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_29"
  type: "ReLU"
  bottom: "1114"
  top: "720"
}
layer {
  name: "Conv_30"
  type: "Convolution"
  bottom: "720"
  top: "1117"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_31"
  type: "ReLU"
  bottom: "1117"
  top: "723"
}
layer {
  name: "Add_32"
  type: "Eltwise"
  bottom: "723"
  bottom: "711"
  top: "724"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Concat_33"
  type: "Concat"
  bottom: "724"
  bottom: "714"
  top: "725"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_34"
  type: "Convolution"
  bottom: "725"
  top: "1120"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_35"
  type: "ReLU"
  bottom: "1120"
  top: "728"
}
layer {
  name: "Conv_36"
  type: "Convolution"
  bottom: "728"
  top: "1123"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 32
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "Relu_37"
  type: "ReLU"
  bottom: "1123"
  top: "731"
}
layer {
  name: "Conv_38"
  type: "Convolution"
  bottom: "731"
  top: "1126"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_39"
  type: "ReLU"
  bottom: "1126"
  top: "734"
}
layer {
  name: "Conv_40"
  type: "Convolution"
  bottom: "734"
  top: "1129"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_41"
  type: "ReLU"
  bottom: "1129"
  top: "737"
}
layer {
  name: "Conv_42"
  type: "Convolution"
  bottom: "734"
  top: "1132"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_43"
  type: "ReLU"
  bottom: "1132"
  top: "740"
}
layer {
  name: "Conv_44"
  type: "Convolution"
  bottom: "737"
  top: "1135"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_45"
  type: "ReLU"
  bottom: "1135"
  top: "743"
}
layer {
  name: "Conv_46"
  type: "Convolution"
  bottom: "743"
  top: "1138"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 32
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_47"
  type: "ReLU"
  bottom: "1138"
  top: "746"
}
layer {
  name: "Conv_48"
  type: "Convolution"
  bottom: "746"
  top: "1141"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_49"
  type: "ReLU"
  bottom: "1141"
  top: "749"
}
layer {
  name: "Add_50"
  type: "Eltwise"
  bottom: "749"
  bottom: "737"
  top: "750"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Conv_51"
  type: "Convolution"
  bottom: "750"
  top: "1144"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_52"
  type: "ReLU"
  bottom: "1144"
  top: "753"
}
layer {
  name: "Conv_53"
  type: "Convolution"
  bottom: "753"
  top: "1147"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 32
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_54"
  type: "ReLU"
  bottom: "1147"
  top: "756"
}
layer {
  name: "Conv_55"
  type: "Convolution"
  bottom: "756"
  top: "1150"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_56"
  type: "ReLU"
  bottom: "1150"
  top: "759"
}
layer {
  name: "Add_57"
  type: "Eltwise"
  bottom: "759"
  bottom: "750"
  top: "760"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Conv_58"
  type: "Convolution"
  bottom: "760"
  top: "1153"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_59"
  type: "ReLU"
  bottom: "1153"
  top: "763"
}
layer {
  name: "Conv_60"
  type: "Convolution"
  bottom: "763"
  top: "1156"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 32
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_61"
  type: "ReLU"
  bottom: "1156"
  top: "766"
}
layer {
  name: "Conv_62"
  type: "Convolution"
  bottom: "766"
  top: "1159"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_63"
  type: "ReLU"
  bottom: "1159"
  top: "769"
}
layer {
  name: "Add_64"
  type: "Eltwise"
  bottom: "769"
  bottom: "760"
  top: "770"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Concat_65"
  type: "Concat"
  bottom: "770"
  bottom: "740"
  top: "771"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_66"
  type: "Convolution"
  bottom: "771"
  top: "1162"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_67"
  type: "ReLU"
  bottom: "1162"
  top: "774"
}
layer {
  name: "Conv_68"
  type: "Convolution"
  bottom: "774"
  top: "1165"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "Relu_69"
  type: "ReLU"
  bottom: "1165"
  top: "777"
}
layer {
  name: "Conv_70"
  type: "Convolution"
  bottom: "777"
  top: "1168"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_71"
  type: "ReLU"
  bottom: "1168"
  top: "780"
}
layer {
  name: "Conv_72"
  type: "Convolution"
  bottom: "777"
  top: "1171"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_73"
  type: "ReLU"
  bottom: "1171"
  top: "783"
}
layer {
  name: "Conv_74"
  type: "Convolution"
  bottom: "780"
  top: "1174"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_75"
  type: "ReLU"
  bottom: "1174"
  top: "786"
}
layer {
  name: "Conv_76"
  type: "Convolution"
  bottom: "786"
  top: "1177"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_77"
  type: "ReLU"
  bottom: "1177"
  top: "789"
}
layer {
  name: "Conv_78"
  type: "Convolution"
  bottom: "789"
  top: "1180"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_79"
  type: "ReLU"
  bottom: "1180"
  top: "792"
}
layer {
  name: "Add_80"
  type: "Eltwise"
  bottom: "792"
  bottom: "780"
  top: "793"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Conv_81"
  type: "Convolution"
  bottom: "793"
  top: "1183"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_82"
  type: "ReLU"
  bottom: "1183"
  top: "796"
}
layer {
  name: "Conv_83"
  type: "Convolution"
  bottom: "796"
  top: "1186"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_84"
  type: "ReLU"
  bottom: "1186"
  top: "799"
}
layer {
  name: "Conv_85"
  type: "Convolution"
  bottom: "799"
  top: "1189"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_86"
  type: "ReLU"
  bottom: "1189"
  top: "802"
}
layer {
  name: "Add_87"
  type: "Eltwise"
  bottom: "802"
  bottom: "793"
  top: "803"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Conv_88"
  type: "Convolution"
  bottom: "803"
  top: "1192"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_89"
  type: "ReLU"
  bottom: "1192"
  top: "806"
}
layer {
  name: "Conv_90"
  type: "Convolution"
  bottom: "806"
  top: "1195"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_91"
  type: "ReLU"
  bottom: "1195"
  top: "809"
}
layer {
  name: "Conv_92"
  type: "Convolution"
  bottom: "809"
  top: "1198"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_93"
  type: "ReLU"
  bottom: "1198"
  top: "812"
}
layer {
  name: "Add_94"
  type: "Eltwise"
  bottom: "812"
  bottom: "803"
  top: "813"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Concat_95"
  type: "Concat"
  bottom: "813"
  bottom: "783"
  top: "814"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_96"
  type: "Convolution"
  bottom: "814"
  top: "1201"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_97"
  type: "ReLU"
  bottom: "1201"
  top: "817"
}
layer {
  name: "Conv_98"
  type: "Convolution"
  bottom: "817"
  top: "1204"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "Relu_99"
  type: "ReLU"
  bottom: "1204"
  top: "820"
}
layer {
  name: "Conv_100"
  type: "Convolution"
  bottom: "820"
  top: "1207"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_101"
  type: "ReLU"
  bottom: "1207"
  top: "823"
}
layer {
  name: "MaxPool_102"
  type: "Pooling"
  bottom: "823"
  top: "824"
  pooling_param {
    pool: MAX
    kernel_h: 5
    kernel_w: 5
    stride_h: 1
    stride_w: 1
    pad_h: 2
    pad_w: 2
  }
}
layer {
  name: "MaxPool_103"
  type: "Pooling"
  bottom: "823"
  top: "825"
  pooling_param {
    pool: MAX
    kernel_h: 9
    kernel_w: 9
    stride_h: 1
    stride_w: 1
    pad_h: 4
    pad_w: 4
  }
}
layer {
  name: "MaxPool_104"
  type: "Pooling"
  bottom: "823"
  top: "826"
  pooling_param {
    pool: MAX
    kernel_h: 13
    kernel_w: 13
    stride_h: 1
    stride_w: 1
    pad_h: 6
    pad_w: 6
  }
}
layer {
  name: "Concat_105"
  type: "Concat"
  bottom: "823"
  bottom: "824"
  bottom: "825"
  bottom: "826"
  top: "827"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_106"
  type: "Convolution"
  bottom: "827"
  top: "1210"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_107"
  type: "ReLU"
  bottom: "1210"
  top: "830"
}
layer {
  name: "Conv_108"
  type: "Convolution"
  bottom: "830"
  top: "1213"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_109"
  type: "ReLU"
  bottom: "1213"
  top: "833"
}
layer {
  name: "Conv_110"
  type: "Convolution"
  bottom: "830"
  top: "1216"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_111"
  type: "ReLU"
  bottom: "1216"
  top: "836"
}
layer {
  name: "Conv_112"
  type: "Convolution"
  bottom: "833"
  top: "1219"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_113"
  type: "ReLU"
  bottom: "1219"
  top: "839"
}
layer {
  name: "Conv_114"
  type: "Convolution"
  bottom: "839"
  top: "1222"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_115"
  type: "ReLU"
  bottom: "1222"
  top: "842"
}
layer {
  name: "Conv_116"
  type: "Convolution"
  bottom: "842"
  top: "1225"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_117"
  type: "ReLU"
  bottom: "1225"
  top: "845"
}
layer {
  name: "Concat_118"
  type: "Concat"
  bottom: "845"
  bottom: "836"
  top: "846"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_119"
  type: "Convolution"
  bottom: "846"
  top: "1228"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_120"
  type: "ReLU"
  bottom: "1228"
  top: "849"
}
layer {
  name: "Conv_121"
  type: "Convolution"
  bottom: "849"
  top: "1231"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_122"
  type: "ReLU"
  bottom: "1231"
  top: "852"
}
layer {
  name: "ConvTranspose_123"
  type: "Deconvolution"
  bottom: "852"
  top: "853"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 0
    pad_w: 0
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "Concat_124"
  type: "Concat"
  bottom: "853"
  bottom: "817"
  top: "854"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_125"
  type: "Convolution"
  bottom: "854"
  top: "1234"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_126"
  type: "ReLU"
  bottom: "1234"
  top: "857"
}
layer {
  name: "Conv_127"
  type: "Convolution"
  bottom: "854"
  top: "1237"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_128"
  type: "ReLU"
  bottom: "1237"
  top: "860"
}
layer {
  name: "Conv_129"
  type: "Convolution"
  bottom: "857"
  top: "1240"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_130"
  type: "ReLU"
  bottom: "1240"
  top: "863"
}
layer {
  name: "Conv_131"
  type: "Convolution"
  bottom: "863"
  top: "1243"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_132"
  type: "ReLU"
  bottom: "1243"
  top: "866"
}
layer {
  name: "Conv_133"
  type: "Convolution"
  bottom: "866"
  top: "1246"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_134"
  type: "ReLU"
  bottom: "1246"
  top: "869"
}
layer {
  name: "Concat_135"
  type: "Concat"
  bottom: "869"
  bottom: "860"
  top: "870"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_136"
  type: "Convolution"
  bottom: "870"
  top: "1249"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_137"
  type: "ReLU"
  bottom: "1249"
  top: "873"
}
layer {
  name: "Conv_138"
  type: "Convolution"
  bottom: "873"
  top: "1252"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_139"
  type: "ReLU"
  bottom: "1252"
  top: "876"
}
layer {
  name: "ConvTranspose_140"
  type: "Deconvolution"
  bottom: "876"
  top: "877"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 0
    pad_w: 0
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "Concat_141"
  type: "Concat"
  bottom: "877"
  bottom: "774"
  top: "878"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_142"
  type: "Convolution"
  bottom: "878"
  top: "1255"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_143"
  type: "ReLU"
  bottom: "1255"
  top: "881"
}
layer {
  name: "Conv_144"
  type: "Convolution"
  bottom: "878"
  top: "1258"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_145"
  type: "ReLU"
  bottom: "1258"
  top: "884"
}
layer {
  name: "Conv_146"
  type: "Convolution"
  bottom: "881"
  top: "1261"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_147"
  type: "ReLU"
  bottom: "1261"
  top: "887"
}
layer {
  name: "Conv_148"
  type: "Convolution"
  bottom: "887"
  top: "1264"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 32
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_149"
  type: "ReLU"
  bottom: "1264"
  top: "890"
}
layer {
  name: "Conv_150"
  type: "Convolution"
  bottom: "890"
  top: "1267"
  convolution_param {
    num_output: 32
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_151"
  type: "ReLU"
  bottom: "1267"
  top: "893"
}
layer {
  name: "Concat_152"
  type: "Concat"
  bottom: "893"
  bottom: "884"
  top: "894"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_153"
  type: "Convolution"
  bottom: "894"
  top: "1270"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_154"
  type: "ReLU"
  bottom: "1270"
  top: "897"
}
layer {
  name: "Conv_155"
  type: "Convolution"
  bottom: "897"
  top: "1273"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "Relu_156"
  type: "ReLU"
  bottom: "1273"
  top: "900"
}
layer {
  name: "Conv_157"
  type: "Convolution"
  bottom: "900"
  top: "1276"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_158"
  type: "ReLU"
  bottom: "1276"
  top: "903"
}
layer {
  name: "Concat_159"
  type: "Concat"
  bottom: "903"
  bottom: "876"
  top: "904"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_160"
  type: "Convolution"
  bottom: "904"
  top: "1279"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_161"
  type: "ReLU"
  bottom: "1279"
  top: "907"
}
layer {
  name: "Conv_162"
  type: "Convolution"
  bottom: "904"
  top: "1282"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_163"
  type: "ReLU"
  bottom: "1282"
  top: "910"
}
layer {
  name: "Conv_164"
  type: "Convolution"
  bottom: "907"
  top: "1285"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_165"
  type: "ReLU"
  bottom: "1285"
  top: "913"
}
layer {
  name: "Conv_166"
  type: "Convolution"
  bottom: "913"
  top: "1288"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_167"
  type: "ReLU"
  bottom: "1288"
  top: "916"
}
layer {
  name: "Conv_168"
  type: "Convolution"
  bottom: "916"
  top: "1291"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_169"
  type: "ReLU"
  bottom: "1291"
  top: "919"
}
layer {
  name: "Concat_170"
  type: "Concat"
  bottom: "919"
  bottom: "910"
  top: "920"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_171"
  type: "Convolution"
  bottom: "920"
  top: "1294"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_172"
  type: "ReLU"
  bottom: "1294"
  top: "923"
}
layer {
  name: "Conv_173"
  type: "Convolution"
  bottom: "923"
  top: "1297"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "Relu_174"
  type: "ReLU"
  bottom: "1297"
  top: "926"
}
layer {
  name: "Conv_175"
  type: "Convolution"
  bottom: "926"
  top: "1300"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_176"
  type: "ReLU"
  bottom: "1300"
  top: "929"
}
layer {
  name: "Concat_177"
  type: "Concat"
  bottom: "929"
  bottom: "852"
  top: "930"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_178"
  type: "Convolution"
  bottom: "930"
  top: "1303"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_179"
  type: "ReLU"
  bottom: "1303"
  top: "933"
}
layer {
  name: "Conv_180"
  type: "Convolution"
  bottom: "930"
  top: "1306"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_181"
  type: "ReLU"
  bottom: "1306"
  top: "936"
}
layer {
  name: "Conv_182"
  type: "Convolution"
  bottom: "933"
  top: "1309"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_183"
  type: "ReLU"
  bottom: "1309"
  top: "939"
}
layer {
  name: "Conv_184"
  type: "Convolution"
  bottom: "939"
  top: "1312"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_185"
  type: "ReLU"
  bottom: "1312"
  top: "942"
}
layer {
  name: "Conv_186"
  type: "Convolution"
  bottom: "942"
  top: "1315"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_187"
  type: "ReLU"
  bottom: "1315"
  top: "945"
}
layer {
  name: "Concat_188"
  type: "Concat"
  bottom: "945"
  bottom: "936"
  top: "946"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Conv_189"
  type: "Convolution"
  bottom: "946"
  top: "1318"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_190"
  type: "ReLU"
  bottom: "1318"
  top: "949"
}
layer {
  name: "Conv_191"
  type: "Convolution"
  bottom: "897"
  top: "1321"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_192"
  type: "ReLU"
  bottom: "1321"
  top: "952"
}
layer {
  name: "Conv_193"
  type: "Convolution"
  bottom: "952"
  top: "1324"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_194"
  type: "ReLU"
  bottom: "1324"
  top: "955"
}
layer {
  name: "Conv_195"
  type: "Convolution"
  bottom: "955"
  top: "1327"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_196"
  type: "ReLU"
  bottom: "1327"
  top: "958"
}
layer {
  name: "Conv_197"
  type: "Convolution"
  bottom: "958"
  top: "1330"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_198"
  type: "ReLU"
  bottom: "1330"
  top: "961"
}
layer {
  name: "Conv_199"
  type: "Convolution"
  bottom: "961"
  top: "1333"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_200"
  type: "ReLU"
  bottom: "1333"
  top: "964"
}
layer {
  name: "Conv_201"
  type: "Convolution"
  bottom: "964"
  top: "965"
  convolution_param {
    num_output: 4
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_202"
  type: "Convolution"
  bottom: "952"
  top: "1336"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_203"
  type: "ReLU"
  bottom: "1336"
  top: "968"
}
layer {
  name: "Conv_204"
  type: "Convolution"
  bottom: "968"
  top: "1339"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_205"
  type: "ReLU"
  bottom: "1339"
  top: "971"
}
layer {
  name: "Conv_206"
  type: "Convolution"
  bottom: "971"
  top: "1342"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_207"
  type: "ReLU"
  bottom: "1342"
  top: "974"
}
layer {
  name: "Conv_208"
  type: "Convolution"
  bottom: "974"
  top: "1345"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_209"
  type: "ReLU"
  bottom: "1345"
  top: "977"
}
layer {
  name: "Conv_210"
  type: "Convolution"
  bottom: "977"
  top: "978"
  convolution_param {
    num_output: 4
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_211"
  type: "Convolution"
  bottom: "977"
  top: "979"
  convolution_param {
    num_output: 1
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_215"
  type: "Convolution"
  bottom: "923"
  top: "1348"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_216"
  type: "ReLU"
  bottom: "1348"
  top: "985"
}
layer {
  name: "Conv_217"
  type: "Convolution"
  bottom: "985"
  top: "1351"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_218"
  type: "ReLU"
  bottom: "1351"
  top: "988"
}
layer {
  name: "Conv_219"
  type: "Convolution"
  bottom: "988"
  top: "1354"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_220"
  type: "ReLU"
  bottom: "1354"
  top: "991"
}
layer {
  name: "Conv_221"
  type: "Convolution"
  bottom: "991"
  top: "1357"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_222"
  type: "ReLU"
  bottom: "1357"
  top: "994"
}
layer {
  name: "Conv_223"
  type: "Convolution"
  bottom: "994"
  top: "1360"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_224"
  type: "ReLU"
  bottom: "1360"
  top: "997"
}
layer {
  name: "Conv_225"
  type: "Convolution"
  bottom: "997"
  top: "998"
  convolution_param {
    num_output: 4
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_226"
  type: "Convolution"
  bottom: "985"
  top: "1363"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_227"
  type: "ReLU"
  bottom: "1363"
  top: "1001"
}
layer {
  name: "Conv_228"
  type: "Convolution"
  bottom: "1001"
  top: "1366"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_229"
  type: "ReLU"
  bottom: "1366"
  top: "1004"
}
layer {
  name: "Conv_230"
  type: "Convolution"
  bottom: "1004"
  top: "1369"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_231"
  type: "ReLU"
  bottom: "1369"
  top: "1007"
}
layer {
  name: "Conv_232"
  type: "Convolution"
  bottom: "1007"
  top: "1372"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_233"
  type: "ReLU"
  bottom: "1372"
  top: "1010"
}
layer {
  name: "Conv_234"
  type: "Convolution"
  bottom: "1010"
  top: "1011"
  convolution_param {
    num_output: 4
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_235"
  type: "Convolution"
  bottom: "1010"
  top: "1012"
  convolution_param {
    num_output: 1
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_239"
  type: "Convolution"
  bottom: "949"
  top: "1375"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_240"
  type: "ReLU"
  bottom: "1375"
  top: "1018"
}
layer {
  name: "Conv_241"
  type: "Convolution"
  bottom: "1018"
  top: "1378"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_242"
  type: "ReLU"
  bottom: "1378"
  top: "1021"
}
layer {
  name: "Conv_243"
  type: "Convolution"
  bottom: "1021"
  top: "1381"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_244"
  type: "ReLU"
  bottom: "1381"
  top: "1024"
}
layer {
  name: "Conv_245"
  type: "Convolution"
  bottom: "1024"
  top: "1384"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_246"
  type: "ReLU"
  bottom: "1384"
  top: "1027"
}
layer {
  name: "Conv_247"
  type: "Convolution"
  bottom: "1027"
  top: "1387"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_248"
  type: "ReLU"
  bottom: "1387"
  top: "1030"
}
layer {
  name: "Conv_249"
  type: "Convolution"
  bottom: "1030"
  top: "1031"
  convolution_param {
    num_output: 4
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_250"
  type: "Convolution"
  bottom: "1018"
  top: "1390"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_251"
  type: "ReLU"
  bottom: "1390"
  top: "1034"
}
layer {
  name: "Conv_252"
  type: "Convolution"
  bottom: "1034"
  top: "1393"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_253"
  type: "ReLU"
  bottom: "1393"
  top: "1037"
}
layer {
  name: "Conv_254"
  type: "Convolution"
  bottom: "1037"
  top: "1396"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_255"
  type: "ReLU"
  bottom: "1396"
  top: "1040"
}
layer {
  name: "Conv_256"
  type: "Convolution"
  bottom: "1040"
  top: "1399"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Relu_257"
  type: "ReLU"
  bottom: "1399"
  top: "1043"
}
layer {
  name: "Conv_258"
  type: "Convolution"
  bottom: "1043"
  top: "1044"
  convolution_param {
    num_output: 4
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "Conv_259"
  type: "Convolution"
  bottom: "1043"
  top: "1045"
  convolution_param {
    num_output: 1
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}